---
title: "Homework 6 - EM"
author: "Sophie Shan"
date: "`r format(Sys.time(), '%m/%d/%Y')`"
output: html_document

header_includes:
- \usepackage{amsmath}
- \usepackage{amssymb}
- \usepackage{amsthm}
include-before:
- '\newcommand{\bfm}[1]{\ensuremath{\mathbf{#1}}}'
- '\newcommand{\bdm}[1]{\ensuremath{\boldsymbol{#1}}}'
- '$\def \d \bfm{d}$'
- '$\def \e \bfm{e}$'
- '$\def \g \bfm{g}$'
- '$\def \I \bfm{I}$'
- '$\def \l \bfm{l}$'
- '$\def \M \bfm{M}$'
- '$\def \W \bfm{W}$'
- '$\def \y \bfm{y}$'
- '$\def \Y \bfm{Y}$'
- '$\def \x \bfm{x}$'
- '$\def \X \bfm{X}$'
- '$\def \z \bfm{z}$'
- '$\def \thetab \boldsymbol{\theta}$'
- '$\def \betab \boldsymbol{\beta}$'
- '$\def \pib \boldsymbol{\pi}$'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
#install.packages("optimx")

library("optimx")
```


# Question 1:  Not So Simple Univariate Optimization

Let is revisit the problem from the last HW, now using BFGS to fit the model.  Report the results of the various starting values as last time, and comment on the convergence for each of the starting values relative the last HW that uses NR.  What properties about BFGS relative to NR could explain the different behavior in this setting? 

$$f(x) = 1.95 - e^{-2/x} - 2e^{-x^4}.$$

```{r}
# f(x)
f = function(x){
  ## solution
  func = 1.95 - exp(-(2/x)) - 2*exp(-(x^4))
  
  ## end solution
  return(func)
}

# first derivative
f1 = function(x){
  ## solution
  first = 8*(x^3)*exp(-x^4) - (2*exp(-(2/x)))/(x^2) 

  ## end solution
  return(first)
}


# to start the model, can use maxit/tolerance defaults from optimx
set.seed(1)
x_vec = sort(runif(10, 0,5))
tol = 10^-6
fit = list()

## solution

## solution
for(i in 1:length(x_vec)){
  fit[[i]] = optimx(
    par = x_vec[i], 
    fn = f, 
    gr = f1, 
    method = "BFGS",
     control = list(
                trace = 0, 
                maximize = T, 
                abstol= tol
                )
  )
}

do.call(rbind, fit)

#ANSWER: x = 1.44
#Even though we used the same starting values as with NR, it appears that
#the solution doesn't blow up to infinity like the initial values > 1.33 for 
#NR does. 
#Unlike NR, BFGS doesn't utilize the second derivative in its iterative 
#calculations.
#The second derivative becomes flat after ~ 2 so that if you utilize that
#in your calculations (like in NR) your estimate will increase without bound. 

## end solution
```


## EM:  Zero-inflated Poisson 

Revisiting problem 3 from HW5, let us implement an EM-based maximization approach to estimate the model parameters.

Please define the CDLL, E-step, and M-step below as we did in class.   

Then, fill in the relevant portions of the code below. 

Hint for writing the CDLL:  Let $z_i = 1$ represent the true (known) membership to the non-fishing population, and $z_i = 0$ to represent membership to the fishing population.  Start with defining the complete data likelihood based on the non-aggregated likelihood below, then take the log to get the final CDLL form. This will help derive the forms for the E and M-steps.  For the actual fitting, we give some direction in the code below in terms of how to use the table aggregated data by a weighting approach. 

### Expression for Log Likelihood: from the previous HW

Lets rewrite the likelihood for the aggregated form of the data in terms of what it would look like when using the $n$ raw, non-aggregated responses:

$$ 
L(\boldsymbol{\theta}) = \prod_{i=1}^n (\pi + (1-\pi)e^{-\lambda})^{I[y_i=0]}\left((1-\pi)\frac{e^{-\lambda}\lambda^{y_i}}{y_i!}\right)^{I[y_i>0]}
$$

This is a simplified form of the PMF that was given at the beginning of the EM lecture. This corresponds to the following log-likelihood

$$\mathcal{l}(\boldsymbol{\theta}) = \sum_{i=1}^n I[y_i=0]\log(\pi + (1-\pi)e^{-\lambda}) + I[y_i>0]\left(\log(1-\pi) -\lambda + {y_i}\log(\lambda) + \log{y_i!}\right)$$

Therefore, if $y > 0$, we know automatically that that individual is from the fishing population.    


### Expression for Complete Data Log Likelihood: Solution

Start with the CDL.

We observe $Y_i$ but the complete data is a function of both $Y_i$ and $Z_i$. 

Recall from HW 5 that we have:

$\theta = (\pi, \lambda)$

$\pi:$ probability that an individual did not show up to fish

$\lambda:$ mean number of fish caught by those individuals that intended to fish at the park

$z_i:$ true membership (latent variable)

$z_i \sim Ber(\pi)$

$$
z_i = 
\begin{cases} 
1 & \text{if membership to the non-fishing population} , \\
0 & \text{if membership to the fishing population}.
\end{cases}
$$
Thus, $(Y_i|Z_i)= 1 \sim Poi(0)$ and $(Y_i|Z_i = 0) \sim Poi(\lambda)$

$$ 
L_c(\boldsymbol{\theta}|y_i, z_i) \propto \prod_{i=1}^n p(y_i, z_i |\theta) 
= \prod_{i=1}^n p(y_i| z_i, \theta)p(z_i|\theta)
$$
$$
p(z_i|\theta) = (\pi)^{z_i}(1-\pi)^{1-z_i}
$$
$$
p(y_i| z_i, \theta) = p(y_i|z_i=1, \theta)^{z_i}p(y_i|z_i = 0, \theta)^{1-z_i} 
= [I(y_i=0)]^{z_i}(\frac{exp(-\lambda)\lambda^{y_i}}{y_i!})^{1-z_i}
$$
Putting it all together:

$$
L_c(\boldsymbol{\theta}|y_i, z_i) \propto \prod_{i=1}^n p(y_i| z_i, \theta)p(z_i|\theta) = \prod_{i=1}^n [I(y_i=0)]^{z_i}(\frac{exp(-\lambda)\lambda^{y_i}}{y_i!})^{1-z_i} (\pi)^{z_i}(1-\pi)^{1-z_i} = \prod_{i=1}^n [I(y_i=0)\pi]^{z_i}[(\frac{exp(-\lambda)\lambda^{y_i}}{y_i!})(1-\pi)]^{1-z_i}
$$

Now take the log

$$\mathcal{l}_c(\boldsymbol{\theta}|y_i, z_i) = \sum_{i=1}^n z_iI(y_i=0)log(\pi) + (1-z_i)[-\lambda+y_ilog(\lambda)-log(y_i!)] + (1-z_i)log(1-\pi)$$
$$
= \sum_{i=1}^n z_iI(y_i=0)log(\frac{\pi}{1-\pi})+log(1-\pi) + (1-z_i)[-\lambda+y_ilog(\lambda)-log(y_i!)]
$$

### Expression for E-step: Solution

$$
Q(\theta; \theta^{(t)}) = \sum_{i=1}^n(E[z_i|y_i, \theta^{(t)}]I[y_i=0]\log({\frac{\pi}{1-\pi}}))+ log(1-\pi) + (1-E[z_i|y_i, \theta^{(t)}])[-\lambda+y_ilog(\lambda)-log(y_i!)]
$$
$$ 
\begin{align}
E[z_i|y_i, \theta^{(t)}] &= 1*p(z_i = 1|y_i, \theta^{(t)}) + 0*p(z_i = 0|y_i, \theta^{(t)}) \\
&= p(z_i = 1|y_i, \theta^{(t)}) \\
&= \frac{p(y_i|z_i=1, \theta^{(t)})p(z_i = 1|\theta^{(t)})}{p(y_i|\theta^{(t)})} \\
\end{align}
$$
$$
p(y_i|z_i=1, \theta^{(t)}) = I(y_i=0)
$$
$$
p(z_i=1|\theta^{(t)}) = \pi^{(t)}
$$

$$
\begin{align}
p(y_i|\theta^{(t)}) &= p(y_i|z_i=1, \theta^{(t)})p(z_i = 1|\theta^{(t)}) + p(y_i|z_i=0, \theta^{(t)})p(z_i = 0|\theta^{(t)}) \\
&= I(y_i=0)\pi^{(t)} + exp(-\lambda^{(t)})(1-\pi^{(t)})
\end{align}
$$


### Expression for M-step: Solution

$$
\hat\pi = \sum_{i=1}^n \frac{E[z_i|y_i, \theta^{(t)}]}{n}
$$
$$
\hat\lambda = exp(\hat\beta) \text{ which is the intercept from a weighted poisson regression model with weights: } 1-E[z_i|y_i, \theta^{(t)}]
$$


### Code implementation 

```{r}

# data 
y = 0:6
ny = c(3062, 587, 284, 103, 33, 4, 2)

## HINT:  to adjust using relative freq of counts in model/calculations when using aggregated data 
y_weight = ny/sum(ny) 
## For example
print(sum(ny*y)/sum(ny)) # mean of y based on aggregated data in table
## We get the same thing when fitting and intercept only poisson reg model, adjusting for relative freq of counts...
print(exp(glm(y ~ 1, weight = y_weight)$coef))

# to start the model
tol = 10^-8
maxit = 50
iter = 0
eps = Inf
ll = -10000

## create posterior probability matrix
pp = matrix(0,length(y), 2)
colnames(pp) = c("non-fisher", "fisher")

## initialize partion, everything  with count 0 is non-fisher, otherwise fisher
pp[which(y ==0),1] = 1
pp[,2] = 1 - pp[,1]

## now start the EM algorithm
while(eps > tol & iter < maxit){
  
  ## save old ll
    ll0 = ll
  
  ## start M-step
    # pi, 1 x 2 vector
    pi = colSums(pp*y_weight)
    
    # lambda, scalar
    lambda = exp(glm(y ~ 1, family = poisson(), weights = pp[,2]*y_weight)$coef)
  
  ## start E-step
    #update for when y_i = 0
    pp[1,1] = pi[1]/(pi[1] + pi[2]*dpois(y[1], lambda = lambda))
    #subtract the second columns from the first 
    pp[,2] = 1-pp[,1]
    
  ## calculate LL
    
    #get the likelihood of coming from non-fisher/fisher and multiply by posterior prob. 
    L = pi[1]*round(pp[,1]) + pi[2]*dpois(y,lambda = lambda)
    #weighted by the number of people in each group 
    ll = sum(log(L)*ny)

  ## calculate relative change in log likelihood  
    eps  = abs(ll-ll0)/abs(ll0)
  
  ## update iterator
    iter = iter + 1
    if(iter == maxit) warning("Iteration limit reached without convergence")
  
  ## print out info to keep track
    cat(sprintf("Iter: %d logL: %.2f pi1: %.3f lambda: %.3f eps:%f\n",iter, ll,pi[1], lambda, eps))
}

```











